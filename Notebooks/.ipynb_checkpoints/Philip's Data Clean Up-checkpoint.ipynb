{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dependencies\n",
    "from datetime import datetime as dt, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from uszipcode import SearchEngine\n",
    "\n",
    "#Open case close date\n",
    "opencaseclosedate=np.datetime64('2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data files to import\n",
    "url2017='https://hfdapp.houstontx.gov/311/311-Public-Data-Extract-2017.txt'\n",
    "url2018='https://hfdapp.houstontx.gov/311/311-Public-Data-Extract-2018.txt'\n",
    "url2019='https://hfdapp.houstontx.gov/311/311-Public-Data-Extract-2019.txt'\n",
    "url2020='https://hfdapp.houstontx.gov/311/311-Public-Data-Extract-monthly.txt'\n",
    "nullzip=pd.read_csv('../Clean Data Files/311latlngzipcodes.csv',dtype={'calczip':str})\n",
    "\n",
    "#Define dataframe column names and select numeric and date columns\n",
    "cols=['case number','sr location','county','district','neighborhood','tax id','trash quad','recycle quad','trash day','heavy trash day','recycle day','key map',\n",
    "      'management district','department','division','sr type','queue','sla','status','sr create date','due date','date closed','overdue','title','x','y','latitude',\n",
    "      'longitude','channel type']\n",
    "numcols=['latitude','longitude']\n",
    "datecols=['sr create date','due date','date closed']\n",
    "\n",
    "#Create zipcode retrieval function\n",
    "search=SearchEngine(simple_zipcode=False)\n",
    "def zipinfo(lat,lng):\n",
    "    zipdata=search.by_coordinates(lat,lng,radius=3,returns=1)\n",
    "    for zipcode in zipdata:\n",
    "        return zipcode.zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 9979: expected 29 fields, saw 30\\nSkipping line 16339: expected 29 fields, saw 30\\n'\n",
      "b'Skipping line 211068: expected 29 fields, saw 30\\n'\n",
      "b'Skipping line 294299: expected 29 fields, saw 30\\n'\n",
      "b'Skipping line 327924: expected 29 fields, saw 30\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(364664, 29)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create 2017 data frames\n",
    "data2017=pd.read_csv(url2017,header=5,sep='|',error_bad_lines=False)\n",
    "data2017=data2017.drop(data2017.index[0]).reset_index(drop=True)\n",
    "data2017.columns=cols\n",
    "data2017[cols]=data2017[cols].apply(lambda x:x.str.strip()).replace(r'^\\s*$',np.nan,regex=True)\n",
    "data2017[datecols]=data2017[datecols].apply(pd.to_datetime,format='%Y-%m-%d %H:%M:%S',errors='coerce')\n",
    "data2017[numcols]=data2017[numcols].apply(pd.to_numeric,errors='coerce')\n",
    "top2017=data2017['sr type'].value_counts()[lambda x:x>=10000].index.tolist()\n",
    "data2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 124864: expected 29 fields, saw 30\\n'\n",
      "C:\\Users\\phili\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(399953, 29)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create 2018 data frames\n",
    "data2018=pd.read_csv(url2018,header=5,sep='|',error_bad_lines=False)\n",
    "data2018=data2018.drop(data2018.index[0]).reset_index(drop=True)\n",
    "data2018.columns=cols\n",
    "data2018[cols]=data2018[cols].apply(lambda x:x.str.strip()).replace(r'^\\s*$',np.nan,regex=True)\n",
    "data2018[datecols]=data2018[datecols].apply(pd.to_datetime,format='%Y-%m-%d %H:%M:%S',errors='coerce')\n",
    "data2018[numcols]=data2018[numcols].apply(pd.to_numeric,errors='coerce')\n",
    "top2018=data2018['sr type'].value_counts()[lambda x:x>=10000].index.tolist()\n",
    "data2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 86859: expected 29 fields, saw 31\\n'\n",
      "b'Skipping line 124913: expected 29 fields, saw 30\\n'\n",
      "b'Skipping line 144497: expected 29 fields, saw 30\\n'\n",
      "b'Skipping line 218652: expected 29 fields, saw 31\\n'\n",
      "b'Skipping line 349873: expected 29 fields, saw 30\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(395258, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create 2019 data frames\n",
    "data2019=pd.read_csv(url2019,header=5,sep='|',error_bad_lines=False)\n",
    "data2019=data2019.drop(data2019.index[0]).reset_index(drop=True)\n",
    "data2019.columns=cols\n",
    "data2019[cols]=data2019[cols].apply(lambda x:x.str.strip()).replace(r'^\\s*$',np.nan,regex=True)\n",
    "data2019[datecols]=data2019[datecols].apply(pd.to_datetime,format='%Y-%m-%d %H:%M:%S',errors='coerce')\n",
    "data2019[numcols]=data2019[numcols].apply(pd.to_numeric,errors='coerce')\n",
    "top2019=data2019['sr type'].value_counts()[lambda x:x>=10000].index.tolist()\n",
    "data2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25483, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create 2020 data frames\n",
    "data2020=pd.read_csv(url2020,header=5,sep='|',error_bad_lines=False)\n",
    "data2020=data2020.drop(data2020.index[0]).reset_index(drop=True)\n",
    "data2020.columns=cols\n",
    "data2020[cols]=data2020[cols].apply(lambda x:x.str.strip()).replace(r'^\\s*$',np.nan,regex=True)\n",
    "data2020[datecols]=data2020[datecols].apply(pd.to_datetime,format='%Y-%m-%d %H:%M:%S',errors='coerce')\n",
    "data2020[numcols]=data2020[numcols].apply(pd.to_numeric,errors='coerce')\n",
    "top2020=data2020['sr type'].value_counts()[lambda x:x>=10000].index.tolist()\n",
    "data2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092423, 34)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create all complete years dataframe\n",
    "tempdata311=data2017.append([data2018,data2019,data2020])\n",
    "data311=pd.merge(tempdata311,nullzip,on=['latitude','longitude'],how='left')\n",
    "data311['date']=data311['sr create date'].dt.strftime('%Y-%m-%d')\n",
    "data311['year']=data311['sr create date'].dt.strftime('%Y')\n",
    "data311['month']=data311['sr create date'].dt.strftime('%m')\n",
    "data311=data311[pd.notnull(data311['latitude'])]\n",
    "data311['date closed']=np.where(data311['date closed'].isnull()==True,opencaseclosedate,data311['date closed'])\n",
    "data311['truezip']='77'+data311['sr location'].str.extract(r'77(\\d{3}\\-?\\d{0,4})')\n",
    "data311['zipcode']=np.where(data311['truezip'].isnull()==True,data311['calczip'],data311['truezip'])\n",
    "data311['openclosetime']=data311['date closed']-data311['sr create date']\n",
    "data311['daystoclose']=data311['openclosetime']/timedelta(days=1)\n",
    "data311['openduetime']=data311['due date']-data311['sr create date']\n",
    "data311['daysdue']=data311['openduetime']/timedelta(days=1)\n",
    "data311['missedduedate']=np.where(data311['due date']>data311['date closed'],0,1)\n",
    "data311.drop(['x','y','calczip','truezip','openclosetime','openduetime'],axis=1,inplace=True)\n",
    "types311=data311.groupby(['sr type','year'])['case number'].count().unstack('year').reset_index()\n",
    "types311.columns=['sr type','2017','2018','2019','2020']\n",
    "data311.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe containing service requests with around 10000 a year\n",
    "toprequests=sorted(np.unique(top2017+top2018+top2019+top2020))\n",
    "topdata=data311.loc[data311['sr type'].isin(toprequests)].reset_index()\n",
    "topdata.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create csv of number of service requests by type per year\n",
    "types311.to_csv('../Clean Data Files/Houston 311 SR Types by Year.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case number                 0\n",
       "sr location                 0\n",
       "county                   2031\n",
       "district                 2946\n",
       "neighborhood             3968\n",
       "tax id                   2021\n",
       "trash quad             111787\n",
       "recycle quad           114051\n",
       "trash day              111787\n",
       "heavy trash day        112422\n",
       "recycle day            114049\n",
       "key map                     0\n",
       "management district    391664\n",
       "department                  0\n",
       "division                    0\n",
       "sr type                     0\n",
       "queue                       0\n",
       "sla                         0\n",
       "status                      0\n",
       "sr create date              0\n",
       "due date                    6\n",
       "date closed                 0\n",
       "overdue                  5032\n",
       "title                       0\n",
       "latitude                    0\n",
       "longitude                   0\n",
       "channel type                0\n",
       "date                        0\n",
       "year                        0\n",
       "month                       0\n",
       "zipcode                     7\n",
       "daystoclose                 0\n",
       "daysdue                     6\n",
       "missedduedate               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display null values in dataset\n",
    "topdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe of missing zipcodes\n",
    "missingzip=topdata[topdata.zipcode.isnull()]\n",
    "missingzip=missingzip[['latitude','longitude']].reset_index()\n",
    "missingzip.drop(['index'],axis=1,inplace=True)\n",
    "missingzip.drop_duplicates(inplace=True)\n",
    "missingzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get missing zipcodes\n",
    "#zipmiss=missingzip[0:5000]\n",
    "missingzip['calczip']=np.vectorize(zipinfo)(missingzip['latitude'].values,missingzip['longitude'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for zips that cannot be coded\n",
    "nonezips=missingzip.loc[missingzip['calczip']=='None']\n",
    "nonezips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check nullzip file size\n",
    "nullzip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check missingzip file size\n",
    "missingzip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append and verify newnullzip file size\n",
    "newnullzip=nullzip.append([missingzip],sort=False)\n",
    "newnullzip.drop_duplicates(inplace=True)\n",
    "newnullzip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create updated zip csv file\n",
    "newnullzip.to_csv('../Clean Data Files/311latlngzipcodes.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
